{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Level: Machine Learning & Predictive Modeling for DEI Analysis\n",
    "\n",
    "Welcome to the advanced workshop on DEI in the music industry! This notebook covers sophisticated analytical techniques including machine learning, predictive modeling, and advanced statistical methods.\n",
    "\n",
    "## Learning Objectives:\n",
    "- Build machine learning models to predict artist success\n",
    "- Identify bias and discrimination patterns using ML techniques\n",
    "- Perform dimensionality reduction and clustering analysis\n",
    "- Apply advanced feature engineering\n",
    "- Conduct bias detection and fairness analysis\n",
    "- Create recommendation systems for equitable representation\n",
    "\n",
    "## Prerequisites:\n",
    "You should have completed both beginner and intermediate levels, or have solid experience with statistics, pandas, and basic machine learning concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/music_industry_dei_data.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} artists, {df.shape[1]} features\")\n",
    "print(f\"Features: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for ML Models\n",
    "\n",
    "Let's create sophisticated features that capture complex patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced features\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create advanced features for machine learning\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Success metrics per year\n",
    "    df['listeners_per_year'] = df['monthly_listeners'] / df['years_active']\n",
    "    df['streams_per_year'] = df['total_streams'] / df['years_active']\n",
    "    df['albums_per_year'] = df['album_count'] / df['years_active']\n",
    "    df['awards_per_year'] = df['award_wins'] / df['years_active']\n",
    "    \n",
    "    # Platform ratio features\n",
    "    df['spotify_soundcloud_ratio'] = df['spotify_followers'] / (df['soundcloud_followers'] + 1)\n",
    "    df['followers_to_listeners_ratio'] = df['spotify_followers'] / (df['monthly_listeners'] + 1)\n",
    "    \n",
    "    # Success intensity (streams per listener)\n",
    "    df['streams_per_listener'] = df['total_streams'] / (df['monthly_listeners'] + 1)\n",
    "    \n",
    "    # Create interaction features\n",
    "    df['gender_ethnicity'] = df['gender'] + '_' + df['ethnicity']\n",
    "    df['genre_label'] = df['genre'] + '_' + df['label_type']\n",
    "    \n",
    "    # Categorical encoding\n",
    "    le_gender = LabelEncoder()\n",
    "    le_ethnicity = LabelEncoder()\n",
    "    le_genre = LabelEncoder()\n",
    "    le_country = LabelEncoder()\n",
    "    le_label = LabelEncoder()\n",
    "    \n",
    "    df['gender_encoded'] = le_gender.fit_transform(df['gender'])\n",
    "    df['ethnicity_encoded'] = le_ethnicity.fit_transform(df['ethnicity'])\n",
    "    df['genre_encoded'] = le_genre.fit_transform(df['genre'])\n",
    "    df['country_encoded'] = le_country.fit_transform(df['country'])\n",
    "    df['label_encoded'] = le_label.fit_transform(df['label_type'])\n",
    "    \n",
    "    # Success tier (categorical target for classification)\n",
    "    df['success_tier'] = pd.cut(df['monthly_listeners'], \n",
    "                               bins=[0, 5000000, 25000000, 50000000, np.inf],\n",
    "                               labels=['Emerging', 'Rising', 'Mainstream', 'Superstar'])\n",
    "    \n",
    "    return df, le_gender, le_ethnicity, le_genre, le_country, le_label\n",
    "\n",
    "df_engineered, le_gender, le_ethnicity, le_genre, le_country, le_label = engineer_features(df)\n",
    "\n",
    "print(f\"Engineered dataset shape: {df_engineered.shape}\")\n",
    "print(f\"New features created: {set(df_engineered.columns) - set(df.columns)}\")\n",
    "df_engineered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling: Success Prediction\n",
    "\n",
    "Let's build machine learning models to predict artist success and identify important factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "feature_cols = ['years_active', 'album_count', 'gender_encoded', 'ethnicity_encoded', \n",
    "               'genre_encoded', 'country_encoded', 'label_encoded', 'award_wins',\n",
    "               'listeners_per_year', 'albums_per_year', 'awards_per_year',\n",
    "               'spotify_soundcloud_ratio']\n",
    "\n",
    "X = df_engineered[feature_cols]\n",
    "y_listeners = df_engineered['monthly_listeners']\n",
    "y_streams = df_engineered['total_streams']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_listeners, y_test_listeners = train_test_split(\n",
    "    X, y_listeners, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Use scaled data for linear models, original for tree-based models\n",
    "    if name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:\n",
    "        X_train_use, X_test_use = X_train_scaled, X_test_scaled\n",
    "    else:\n",
    "        X_train_use, X_test_use = X_train, X_test\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_use, y_train_listeners)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_use)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test_listeners, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_listeners, y_pred)\n",
    "    r2 = r2_score(y_test_listeners, y_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_use, y_train_listeners, cv=5, scoring='r2')\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2,\n",
    "        'CV_R²_mean': cv_scores.mean(),\n",
    "        'CV_R²_std': cv_scores.std(),\n",
    "        'model': model,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({k: {metric: v[metric] for metric in ['RMSE', 'MAE', 'R²', 'CV_R²_mean', 'CV_R²_std']} \n",
    "                          for k, v in model_results.items()}).T\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df['R²'].idxmax()\n",
    "print(f\"\\nBest performing model: {best_model_name} (R² = {results_df.loc[best_model_name, 'R²']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance and Bias Detection\n",
    "\n",
    "Let's analyze which features are most important for predicting success and identify potential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "# Feature importance analysis\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "else:\n",
    "    # For linear models, use coefficient magnitudes\n",
    "    feature_importance = np.abs(best_model.coef_)\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "plt.title(f'Feature Importance - {best_model_name}')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias detection: Analyze prediction errors by demographic groups\n",
    "test_results = X_test.copy()\n",
    "test_results['actual'] = y_test_listeners\n",
    "test_results['predicted'] = model_results[best_model_name]['predictions']\n",
    "test_results['error'] = test_results['actual'] - test_results['predicted']\n",
    "test_results['abs_error'] = np.abs(test_results['error'])\n",
    "test_results['pct_error'] = (test_results['error'] / test_results['actual']) * 100\n",
    "\n",
    "# Map encoded values back to original categories\n",
    "test_results['gender'] = le_gender.inverse_transform(test_results['gender_encoded'])\n",
    "test_results['ethnicity'] = le_ethnicity.inverse_transform(test_results['ethnicity_encoded'])\n",
    "test_results['genre'] = le_genre.inverse_transform(test_results['genre_encoded'])\n",
    "test_results['label_type'] = le_label.inverse_transform(test_results['label_encoded'])\n",
    "\n",
    "# Analyze bias by gender\n",
    "gender_bias = test_results.groupby('gender').agg({\n",
    "    'error': ['mean', 'std'],\n",
    "    'abs_error': 'mean',\n",
    "    'pct_error': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"BIAS ANALYSIS BY GENDER:\")\n",
    "print(gender_bias)\n",
    "\n",
    "# Analyze bias by ethnicity\n",
    "ethnicity_bias = test_results.groupby('ethnicity').agg({\n",
    "    'error': ['mean', 'std'],\n",
    "    'abs_error': 'mean',\n",
    "    'pct_error': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nBIAS ANALYSIS BY ETHNICITY:\")\n",
    "print(ethnicity_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction bias\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Actual vs Predicted by Gender\n",
    "for i, gender in enumerate(test_results['gender'].unique()):\n",
    "    gender_data = test_results[test_results['gender'] == gender]\n",
    "    axes[0,0].scatter(gender_data['actual'], gender_data['predicted'], \n",
    "                     label=gender, alpha=0.7)\n",
    "axes[0,0].plot([0, test_results['actual'].max()], [0, test_results['actual'].max()], \n",
    "              'k--', label='Perfect Prediction')\n",
    "axes[0,0].set_xlabel('Actual Monthly Listeners')\n",
    "axes[0,0].set_ylabel('Predicted Monthly Listeners')\n",
    "axes[0,0].set_title('Actual vs Predicted by Gender')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Error distribution by Gender\n",
    "sns.boxplot(data=test_results, x='gender', y='pct_error', ax=axes[0,1])\n",
    "axes[0,1].set_title('Prediction Error Distribution by Gender')\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Error by Ethnicity\n",
    "sns.boxplot(data=test_results, x='ethnicity', y='pct_error', ax=axes[1,0])\n",
    "axes[1,0].set_title('Prediction Error Distribution by Ethnicity')\n",
    "axes[1,0].set_xticklabels(axes[1,0].get_xticklabels(), rotation=45)\n",
    "axes[1,0].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Residuals plot\n",
    "axes[1,1].scatter(test_results['predicted'], test_results['error'], alpha=0.7)\n",
    "axes[1,1].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1,1].set_xlabel('Predicted Values')\n",
    "axes[1,1].set_ylabel('Residuals')\n",
    "axes[1,1].set_title('Residuals vs Predicted Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Analysis: Artist Archetypes\n",
    "\n",
    "Let's use unsupervised learning to identify different artist archetypes and analyze their demographic composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "cluster_features = ['monthly_listeners', 'total_streams', 'album_count', 'years_active', \n",
    "                   'award_wins', 'spotify_followers', 'soundcloud_followers']\n",
    "\n",
    "X_cluster = df_engineered[cluster_features]\n",
    "\n",
    "# Scale the data\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose optimal k (look for the elbow)\n",
    "optimal_k = 4  # You can adjust this based on the elbow curve\n",
    "print(f\"Using k = {optimal_k} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_clustered = df_engineered.copy()\n",
    "df_clustered['cluster'] = clusters\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "cluster_summary = df_clustered.groupby('cluster')[cluster_features].mean()\n",
    "print(\"Cluster Characteristics (Mean Values):\")\n",
    "print(cluster_summary.round(0))\n",
    "\n",
    "# Analyze demographic composition of clusters\n",
    "print(\"\\nCluster Demographic Composition:\")\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_clustered[df_clustered['cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_data)} artists):\")\n",
    "    print(f\"  Gender: {cluster_data['gender'].value_counts().to_dict()}\")\n",
    "    print(f\"  Ethnicity: {cluster_data['ethnicity'].value_counts().to_dict()}\")\n",
    "    print(f\"  Top Genres: {cluster_data['genre'].value_counts().head(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.7)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.title('Artist Clusters in PCA Space')\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "# Add cluster centers\n",
    "centers_pca = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], c='red', marker='x', s=300, linewidths=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explains {pca.explained_variance_ratio_.sum():.2%} of total variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Metrics and Bias Quantification\n",
    "\n",
    "Let's implement formal fairness metrics to quantify bias in artist success patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fairness metrics\n",
    "def calculate_fairness_metrics(df, protected_attribute, outcome_variable, threshold_percentile=75):\n",
    "    \"\"\"\n",
    "    Calculate various fairness metrics for a protected attribute\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(df[outcome_variable], threshold_percentile)\n",
    "    df['high_success'] = (df[outcome_variable] >= threshold).astype(int)\n",
    "    \n",
    "    metrics = {}\n",
    "    groups = df[protected_attribute].unique()\n",
    "    \n",
    "    # Statistical Parity (Demographic Parity)\n",
    "    group_rates = {}\n",
    "    for group in groups:\n",
    "        group_data = df[df[protected_attribute] == group]\n",
    "        positive_rate = group_data['high_success'].mean()\n",
    "        group_rates[group] = positive_rate\n",
    "    \n",
    "    # Calculate max difference in positive rates\n",
    "    max_diff = max(group_rates.values()) - min(group_rates.values())\n",
    "    metrics['statistical_parity_diff'] = max_diff\n",
    "    \n",
    "    # Equalized Odds (True Positive Rate equality)\n",
    "    # For this context, we'll use average success rate as proxy\n",
    "    avg_success_by_group = df.groupby(protected_attribute)[outcome_variable].mean()\n",
    "    success_ratio = avg_success_by_group.max() / avg_success_by_group.min()\n",
    "    metrics['success_ratio'] = success_ratio\n",
    "    \n",
    "    # Representation in top tier\n",
    "    top_tier = df[df['high_success'] == 1]\n",
    "    top_tier_composition = top_tier[protected_attribute].value_counts(normalize=True)\n",
    "    overall_composition = df[protected_attribute].value_counts(normalize=True)\n",
    "    \n",
    "    representation_ratio = {}\n",
    "    for group in groups:\n",
    "        top_pct = top_tier_composition.get(group, 0)\n",
    "        overall_pct = overall_composition.get(group, 0)\n",
    "        if overall_pct > 0:\n",
    "            representation_ratio[group] = top_pct / overall_pct\n",
    "        else:\n",
    "            representation_ratio[group] = 0\n",
    "    \n",
    "    metrics['group_rates'] = group_rates\n",
    "    metrics['avg_success_by_group'] = avg_success_by_group.to_dict()\n",
    "    metrics['representation_ratio'] = representation_ratio\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate fairness metrics for gender\n",
    "gender_fairness = calculate_fairness_metrics(df_engineered, 'gender', 'monthly_listeners')\n",
    "\n",
    "print(\"FAIRNESS ANALYSIS - GENDER:\")\n",
    "print(f\"Statistical Parity Difference: {gender_fairness['statistical_parity_diff']:.3f}\")\n",
    "print(f\"Success Ratio (Max/Min): {gender_fairness['success_ratio']:.3f}\")\n",
    "print(f\"High Success Rates by Gender: {gender_fairness['group_rates']}\")\n",
    "print(f\"Average Success by Gender: {gender_fairness['avg_success_by_group']}\")\n",
    "print(f\"Representation Ratio in Top Tier: {gender_fairness['representation_ratio']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Calculate fairness metrics for ethnicity\n",
    "ethnicity_fairness = calculate_fairness_metrics(df_engineered, 'ethnicity', 'monthly_listeners')\n",
    "\n",
    "print(\"FAIRNESS ANALYSIS - ETHNICITY:\")\n",
    "print(f\"Statistical Parity Difference: {ethnicity_fairness['statistical_parity_diff']:.3f}\")\n",
    "print(f\"Success Ratio (Max/Min): {ethnicity_fairness['success_ratio']:.3f}\")\n",
    "print(f\"High Success Rates by Ethnicity:\")\n",
    "for eth, rate in ethnicity_fairness['group_rates'].items():\n",
    "    print(f\"  {eth}: {rate:.3f}\")\n",
    "print(f\"Representation Ratio in Top Tier:\")\n",
    "for eth, ratio in ethnicity_fairness['representation_ratio'].items():\n",
    "    print(f\"  {eth}: {ratio:.3f} ({'Over' if ratio > 1 else 'Under'}-represented)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System for Equitable Representation\n",
    "\n",
    "Let's create a simple recommendation system to identify underrepresented artists who deserve more attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_equity_score(df):\n",
    "    \"\"\"\n",
    "    Create an equity score that identifies underrepresented artists with high potential\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Quality metrics (normalized to 0-1)\n",
    "    df['quality_score'] = (\n",
    "        (df['award_wins'] / df['award_wins'].max()) * 0.3 +\n",
    "        (df['albums_per_year'] / df['albums_per_year'].max()) * 0.2 +\n",
    "        (df['years_active'] / df['years_active'].max()) * 0.2 +\n",
    "        (df['streams_per_listener'] / df['streams_per_listener'].max()) * 0.3\n",
    "    )\n",
    "    \n",
    "    # Current visibility (inverse - lower visibility = higher equity need)\n",
    "    df['visibility_score'] = 1 - (df['monthly_listeners'] / df['monthly_listeners'].max())\n",
    "    \n",
    "    # Demographic penalty (higher for underrepresented groups)\n",
    "    demographic_weights = {\n",
    "        'Female': 1.3,  # Female artists are underrepresented at top levels\n",
    "        'Male': 1.0\n",
    "    }\n",
    "    \n",
    "    ethnicity_weights = {\n",
    "        'White': 1.0,\n",
    "        'Black': 1.2,\n",
    "        'Latino': 1.2,\n",
    "        'Asian': 1.3,\n",
    "        'Mixed': 1.2,\n",
    "        'Middle Eastern': 1.4\n",
    "    }\n",
    "    \n",
    "    df['demo_weight'] = (df['gender'].map(demographic_weights) * \n",
    "                        df['ethnicity'].map(ethnicity_weights))\n",
    "    \n",
    "    # Independent label boost\n",
    "    df['label_boost'] = df['label_type'].map({'Independent': 1.2, 'Major': 1.0})\n",
    "    \n",
    "    # Calculate final equity score\n",
    "    df['equity_score'] = (df['quality_score'] * 0.4 + \n",
    "                         df['visibility_score'] * 0.3 + \n",
    "                         df['demo_weight'] * 0.2 + \n",
    "                         df['label_boost'] * 0.1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_equity = create_equity_score(df_engineered)\n",
    "\n",
    "# Top recommendations for equitable promotion\n",
    "top_equity = df_equity.nlargest(15, 'equity_score')[[\n",
    "    'artist_name', 'gender', 'ethnicity', 'genre', 'country', 'label_type',\n",
    "    'monthly_listeners', 'quality_score', 'visibility_score', 'equity_score'\n",
    "]].round(3)\n",
    "\n",
    "print(\"TOP 15 ARTISTS FOR EQUITABLE PROMOTION:\")\n",
    "print(top_equity.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize equity scores\n",
    "fig = make_subplots(rows=2, cols=2, \n",
    "                    subplot_titles=['Equity Score by Gender', 'Equity Score by Ethnicity',\n",
    "                                  'Quality vs Visibility', 'Equity Score Distribution'],\n",
    "                    specs=[[{\"type\": \"box\"}, {\"type\": \"box\"}],\n",
    "                          [{\"type\": \"scatter\"}, {\"type\": \"histogram\"}]])\n",
    "\n",
    "# Box plot by gender\n",
    "for gender in df_equity['gender'].unique():\n",
    "    gender_data = df_equity[df_equity['gender'] == gender]['equity_score']\n",
    "    fig.add_trace(go.Box(y=gender_data, name=gender, showlegend=False), row=1, col=1)\n",
    "\n",
    "# Box plot by ethnicity\n",
    "for ethnicity in df_equity['ethnicity'].unique():\n",
    "    eth_data = df_equity[df_equity['ethnicity'] == ethnicity]['equity_score']\n",
    "    fig.add_trace(go.Box(y=eth_data, name=ethnicity, showlegend=False), row=1, col=2)\n",
    "\n",
    "# Scatter: Quality vs Visibility\n",
    "fig.add_trace(go.Scatter(x=df_equity['quality_score'], y=df_equity['visibility_score'],\n",
    "                        mode='markers', \n",
    "                        marker=dict(color=df_equity['equity_score'], colorscale='Viridis',\n",
    "                                  showscale=True, colorbar=dict(title=\"Equity Score\")),\n",
    "                        text=df_equity['artist_name'],\n",
    "                        showlegend=False), row=2, col=1)\n",
    "\n",
    "# Histogram of equity scores\n",
    "fig.add_trace(go.Histogram(x=df_equity['equity_score'], nbinsx=20, showlegend=False), row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Equity Analysis Dashboard\")\n",
    "fig.update_xaxes(title_text=\"Quality Score\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Visibility Score\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Equity Score\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Insights and Recommendations\n",
    "\n",
    "Based on your advanced analysis, provide comprehensive insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Advanced Insights:\n",
    "\n",
    "1. **Machine Learning Model Performance**: [Analyze which model performed best and what this tells us about the predictability of success]\n",
    "\n",
    "2. **Feature Importance**: [Discuss the most important factors for predicting success and their implications for DEI]\n",
    "\n",
    "3. **Bias Detection**: [Analyze the systematic biases found in the model predictions and their real-world implications]\n",
    "\n",
    "4. **Artist Archetypes**: [Describe the different clusters/archetypes found and their demographic composition]\n",
    "\n",
    "5. **Fairness Metrics**: [Interpret the fairness metrics and what they reveal about equity in the music industry]\n",
    "\n",
    "6. **Equity Recommendations**: [Discuss the recommended artists and the rationale behind the equity scoring system]\n",
    "\n",
    "7. **Systemic Issues**: [Identify systemic issues that contribute to inequality in the music industry]\n",
    "\n",
    "8. **Actionable Solutions**: [Propose specific, data-driven solutions for improving DEI in the music industry]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Limitations and Future Work\n",
    "\n",
    "### Limitations of This Analysis:\n",
    "- Small sample size may not represent the full music industry\n",
    "- Success metrics are limited to streaming/followers (missing radio play, live performance revenue, etc.)\n",
    "- Temporal dynamics not captured (how has representation changed over time?)\n",
    "- Selection bias: only includes already successful artists\n",
    "- Intersectionality not fully explored (e.g., gender × ethnicity interactions)\n",
    "\n",
    "### Future Research Directions:\n",
    "- Longitudinal analysis to track changes over time\n",
    "- Causal inference methods to identify causal factors vs correlations\n",
    "- Natural language processing on lyrics and music reviews\n",
    "- Network analysis of collaborations and industry connections\n",
    "- Integration of additional data sources (radio play, concert attendance, etc.)\n",
    "- Deeper intersectional analysis\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed an advanced analysis using:\n",
    "\n",
    "- **Machine Learning**: Predictive modeling with multiple algorithms\n",
    "- **Bias Detection**: Systematic analysis of algorithmic bias\n",
    "- **Clustering**: Unsupervised learning to identify artist archetypes\n",
    "- **Fairness Metrics**: Quantitative assessment of equity\n",
    "- **Recommendation Systems**: Data-driven approach to promoting equity\n",
    "- **Advanced Visualization**: Interactive and multi-dimensional plots\n",
    "\n",
    "This analysis demonstrates how advanced data science techniques can be applied to understand and address DEI challenges in creative industries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}